{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf11401",
   "metadata": {},
   "source": [
    "## 1. Setup and Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3faa1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "\n",
      "No GPU detected. Running on CPU.\n",
      "In Colab: Runtime > Change runtime type > Hardware accelerator > GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Check TensorFlow version and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check for GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"GPU ENABLED: {len(gpus)} GPU(s) detected\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"  GPU {i}: {gpu.name}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo GPU detected. Running on CPU.\")\n",
    "    print(\"In Colab: Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2307c45d",
   "metadata": {},
   "source": [
    "## 2. Install Required Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023efe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting automatic package installation...\n",
      "\n",
      "🔧 Installing required packages for blank environment...\n",
      "============================================================\n",
      "\n",
      "📦 Installing tensorflow>=2.10.0...\n",
      "\n",
      "📦 Installing numpy>=1.21.0...\n",
      "\n",
      "📦 Installing pillow>=9.0.0...\n",
      "\n",
      "📦 Installing tqdm>=4.64.0...\n",
      "\n",
      "📦 Installing matplotlib>=3.5.0...\n",
      "\n",
      "============================================================\n",
      "✅ Package installation completed!\n",
      "============================================================\n",
      "\n",
      "⚠️ IMPORTANT: For GPU support, ensure you have:\n",
      "  1. NVIDIA GPU with CUDA Compute Capability 3.5+\n",
      "  2. CUDA Toolkit 11.2 or higher\n",
      "  3. cuDNN 8.1 or higher\n",
      "\n",
      "💡 After installation, restart the kernel if needed.\n",
      "   Kernel > Restart Kernel\n"
     ]
    }
   ],
   "source": [
    "# AUTOMATIC INSTALLATION - Run this cell to install all required packages\n",
    "# This cell will install packages automatically for a blank Python environment\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    packages = [\n",
    "        'tensorflow>=2.10.0',  # TensorFlow with GPU support\n",
    "        'numpy>=1.21.0',\n",
    "        'pillow>=9.0.0',\n",
    "        'tqdm>=4.64.0',\n",
    "        'matplotlib>=3.5.0',\n",
    "    ]\n",
    "    \n",
    "    print(\"🔧 Installing required packages for blank environment...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"\\n📦 Installing {package}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"⚠️ Error installing {package}: {e}\")\n",
    "            print(\"Continuing with next package...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅ Package installation completed!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n⚠️ IMPORTANT: For GPU support, ensure you have:\")\n",
    "    print(\"  1. NVIDIA GPU with CUDA Compute Capability 3.5+\")\n",
    "    print(\"  2. CUDA Toolkit 11.2 or higher\")\n",
    "    print(\"  3. cuDNN 8.1 or higher\")\n",
    "    print(\"\\n💡 After installation, restart the kernel if needed.\")\n",
    "    print(\"   Kernel > Restart Kernel\")\n",
    "\n",
    "# Run installation automatically\n",
    "print(\"Starting automatic package installation...\\n\")\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395ca172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ requirements.txt created!\n",
      "\n",
      "To install all packages, run in terminal:\n",
      "  pip install -r requirements.txt\n",
      "\n",
      "For GPU support, ensure CUDA and cuDNN are installed.\n"
     ]
    }
   ],
   "source": [
    "# Create requirements.txt file for easy package management\n",
    "requirements_content = \"\"\"# Image Captioning Project Requirements\n",
    "# Install all with: pip install -r requirements.txt\n",
    "\n",
    "tensorflow>=2.10.0\n",
    "numpy>=1.21.0\n",
    "pillow>=9.0.0\n",
    "tqdm>=4.64.0\n",
    "matplotlib>=3.5.0\n",
    "\n",
    "# Optional: For Kaggle dataset download\n",
    "# kaggle>=1.5.12\n",
    "\"\"\"\n",
    "\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    f.write(requirements_content)\n",
    "\n",
    "print(\"✓ requirements.txt created!\")\n",
    "print(\"\\nTo install all packages, run in terminal:\")\n",
    "print(\"  pip install -r requirements.txt\")\n",
    "print(\"\\nFor GPU support, ensure CUDA and cuDNN are installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9924cc",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada95fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pickle import dump, load\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import add, concatenate, multiply, RepeatVector, Reshape, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5eb3b3",
   "metadata": {},
   "source": [
    "## 4. Configure Local Dataset Paths\n",
    "\n",
    "Set up paths to your local Flickr8k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce545fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Configuration:\n",
      "  Text files: C:\\Users\\jebar\\OneDrive\\Bureau\\Deep Learning\\Flickr8k\\Flickr8k_text\n",
      "  Images: C:\\Users\\jebar\\OneDrive\\Bureau\\Deep Learning\\Flickr8k\\Flicker8k_Dataset\n",
      "\n",
      "✓ Dataset paths found!\n",
      "  Images found: 8091 files\n"
     ]
    }
   ],
   "source": [
    "# LOCAL SETUP: Configure your dataset paths here\n",
    "# Download Flickr8k from: https://www.kaggle.com/datasets/adityajn105/flickr8k\n",
    "\n",
    "# Option 1: Set your local paths (RECOMMENDED)\n",
    "base_path = r\"path to your dataset\"\n",
    "dataset_text = os.path.join(base_path, \"Flickr8k_text\")\n",
    "dataset_images = os.path.join(base_path, \"Flicker8k_Dataset\")\n",
    "\n",
    "# Option 2: Or use relative paths if dataset is in the same directory\n",
    "# base_path = \"Flickr8k\"\n",
    "# dataset_text = os.path.join(base_path, \"Flickr8k_text\")\n",
    "# dataset_images = os.path.join(base_path, \"Flicker8k_Dataset\")\n",
    "\n",
    "print(\"Dataset Configuration:\")\n",
    "print(f\"  Text files: {dataset_text}\")\n",
    "print(f\"  Images: {dataset_images}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if os.path.exists(dataset_text) and os.path.exists(dataset_images):\n",
    "    print(\"\\n✓ Dataset paths found!\")\n",
    "    print(f\"  Images found: {len([f for f in os.listdir(dataset_images) if f.endswith(('.jpg', '.png'))])} files\")\n",
    "else:\n",
    "    print(\"\\n⚠ WARNING: Dataset paths not found!\")\n",
    "    print(\"  Please update the paths above to point to your Flickr8k dataset location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98971a72",
   "metadata": {},
   "source": [
    "## 5. Download Dataset (If Needed)\n",
    "\n",
    "If you don't have the Flickr8k dataset yet, download it from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f0a07",
   "metadata": {},
   "source": [
    "## 6. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5c02e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined!\n"
     ]
    }
   ],
   "source": [
    "def load_doc(filename):\n",
    "    \"\"\"Load a text file into memory\"\"\"\n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def all_img_captions(filename):\n",
    "    \"\"\"Extract all image captions from the token file\"\"\"\n",
    "    file = load_doc(filename)\n",
    "    captions = file.split('\\n')\n",
    "    descriptions = {}\n",
    "    for caption in captions[:-1]:\n",
    "        img, caption = caption.split('\\t')\n",
    "        if img[:-2] not in descriptions:\n",
    "            descriptions[img[:-2]] = [caption]\n",
    "        else:\n",
    "            descriptions[img[:-2]].append(caption)\n",
    "    return descriptions\n",
    "\n",
    "print(\"Data loading functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1fb5c1",
   "metadata": {},
   "source": [
    "## 7. Text Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f50ba1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning functions defined!\n"
     ]
    }
   ],
   "source": [
    "def cleaning_text(captions):\n",
    "    \"\"\"Clean and preprocess text captions\"\"\"\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for img, caps in captions.items():\n",
    "        for i, img_caption in enumerate(caps):\n",
    "            img_caption = img_caption.replace(\"-\", \" \")\n",
    "            desc = img_caption.split()\n",
    "            desc = [word.lower() for word in desc]\n",
    "            desc = [word.translate(table) for word in desc]\n",
    "            desc = [word for word in desc if len(word) > 1]\n",
    "            desc = [word for word in desc if word.isalpha()]\n",
    "            img_caption = ' '.join(desc)\n",
    "            captions[img][i] = img_caption\n",
    "    return captions\n",
    "\n",
    "def text_vocabulary(descriptions):\n",
    "    \"\"\"Build vocabulary of all unique words\"\"\"\n",
    "    vocab = set()\n",
    "    for key in descriptions.keys():\n",
    "        [vocab.update(d.split()) for d in descriptions[key]]\n",
    "    return vocab\n",
    "\n",
    "def save_descriptions(descriptions, filename):\n",
    "    \"\"\"Save descriptions to file\"\"\"\n",
    "    lines = []\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(key + '\\t' + desc)\n",
    "    data = \"\\n\".join(lines)\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(data)\n",
    "\n",
    "print(\"Text cleaning functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dec212",
   "metadata": {},
   "source": [
    "## 8. Prepare Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99aae2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing captions...\n",
      "Loaded 8092 images with captions\n",
      "Vocabulary size: 8422 words\n",
      "descriptions.txt created successfully!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"descriptions.txt\"):\n",
    "    print(\"descriptions.txt already exists. Skipping preprocessing...\")\n",
    "else:\n",
    "    print(\"Processing captions...\")\n",
    "    filename = os.path.join(dataset_text, \"Flickr8k.token.txt\")\n",
    "    \n",
    "    # Load all captions\n",
    "    descriptions = all_img_captions(filename)\n",
    "    print(f\"Loaded {len(descriptions)} images with captions\")\n",
    "    \n",
    "    # Clean descriptions\n",
    "    clean_descriptions = cleaning_text(descriptions)\n",
    "    \n",
    "    # Build vocabulary\n",
    "    vocabulary = text_vocabulary(clean_descriptions)\n",
    "    print(f\"Vocabulary size: {len(vocabulary)} words\")\n",
    "    \n",
    "    # Save to file\n",
    "    save_descriptions(clean_descriptions, \"descriptions.txt\")\n",
    "    print(\"descriptions.txt created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c6490",
   "metadata": {},
   "source": [
    "## 9. Feature Extraction with Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca1e4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction function defined!\n"
     ]
    }
   ],
   "source": [
    "def extract_features(directory, batch_size=16):\n",
    "    \"\"\"Extract features from images using Xception model\"\"\"\n",
    "    # Load Xception model\n",
    "    model = Xception(include_top=False, pooling='avg', weights='imagenet')\n",
    "    print(\"Xception model loaded!\")\n",
    "    \n",
    "    features = {}\n",
    "    valid_images = ['.jpg', '.jpeg', '.png']\n",
    "    \n",
    "    # Get all image paths\n",
    "    image_paths = []\n",
    "    for img in os.listdir(directory):\n",
    "        ext = os.path.splitext(img)[1].lower()\n",
    "        if ext in valid_images:\n",
    "            image_paths.append(img)\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images to process\")\n",
    "    \n",
    "    # Process in batches for efficiency on GPU\n",
    "    for i in tqdm(range(0, len(image_paths), batch_size), desc=\"Extracting features\"):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        valid_batch_names = []\n",
    "        \n",
    "        for img in batch_paths:\n",
    "            filepath = os.path.join(directory, img)\n",
    "            try:\n",
    "                image = Image.open(filepath)\n",
    "                image = image.resize((299, 299))\n",
    "                image = np.array(image)\n",
    "                \n",
    "                # Handle grayscale\n",
    "                if len(image.shape) == 2:\n",
    "                    image = np.stack([image] * 3, axis=-1)\n",
    "                # Handle RGBA\n",
    "                elif image.shape[2] == 4:\n",
    "                    image = image[:, :, :3]\n",
    "                \n",
    "                image = preprocess_input(image)\n",
    "                batch_images.append(image)\n",
    "                valid_batch_names.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if batch_images:\n",
    "            batch_array = np.array(batch_images)\n",
    "            batch_features = model.predict(batch_array, verbose=0)\n",
    "            \n",
    "            for idx, img_name in enumerate(valid_batch_names):\n",
    "                features[img_name] = batch_features[idx].reshape(1, -1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Feature extraction function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da103d00",
   "metadata": {},
   "source": [
    "## 10. Extract and Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158bbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from images...\n",
      "This may take several minutes with GPU...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Xception model loaded!\n",
      "Found 8091 images to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|███████████████████████████████████████████████████████████| 506/506 [26:00<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted and saved for 8091 images!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"features.pkl\"):\n",
    "    print(\"features.pkl already exists. Loading features...\")\n",
    "    features = load(open(\"features.pkl\", \"rb\"))\n",
    "    print(f\"Loaded features for {len(features)} images\")\n",
    "else:\n",
    "    print(\"Extracting features from images...\")\n",
    "    print(\"This may take several minutes with GPU...\")\n",
    "    \n",
    "    features = extract_features(dataset_images, batch_size=16)\n",
    "    \n",
    "    # Save features\n",
    "    dump(features, open(\"features.pkl\", \"wb\"))\n",
    "    print(f\"Features extracted and saved for {len(features)} images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fb901",
   "metadata": {},
   "source": [
    "## 11. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a19bdbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 6000 images\n",
      "Loaded descriptions for 6000 images\n",
      "Loaded features for 6000 images\n"
     ]
    }
   ],
   "source": [
    "def load_photos(filename):\n",
    "    \"\"\"Load list of photo identifiers\"\"\"\n",
    "    file = load_doc(filename)\n",
    "    photos = file.split(\"\\n\")[:-1]\n",
    "    return photos\n",
    "\n",
    "def load_clean_descriptions(filename, photos):\n",
    "    \"\"\"Load clean descriptions for photos\"\"\"\n",
    "    file = load_doc(filename)\n",
    "    descriptions = {}\n",
    "    for line in file.split(\"\\n\"):\n",
    "        words = line.split()\n",
    "        if len(words) < 1:\n",
    "            continue\n",
    "        image, image_caption = words[0], words[1:]\n",
    "        if image in photos:\n",
    "            if image not in descriptions:\n",
    "                descriptions[image] = []\n",
    "            desc = '<start> ' + \" \".join(image_caption) + ' <end>'\n",
    "            descriptions[image].append(desc)\n",
    "    return descriptions\n",
    "\n",
    "def load_features(photos, all_features):\n",
    "    \"\"\"Load features for specific photos\"\"\"\n",
    "    return {k: all_features[k] for k in photos if k in all_features}\n",
    "\n",
    "# Load training set\n",
    "train_filename = os.path.join(dataset_text, \"Flickr_8k.trainImages.txt\")\n",
    "train_imgs = load_photos(train_filename)\n",
    "train_descriptions = load_clean_descriptions(\"descriptions.txt\", train_imgs)\n",
    "train_features = load_features(train_imgs, features)\n",
    "\n",
    "print(f\"Training set: {len(train_imgs)} images\")\n",
    "print(f\"Loaded descriptions for {len(train_descriptions)} images\")\n",
    "print(f\"Loaded features for {len(train_features)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ac01e",
   "metadata": {},
   "source": [
    "## 12. Create Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03468b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tokenizer...\n",
      "Tokenizer created and saved!\n",
      "Vocabulary size: 7318\n"
     ]
    }
   ],
   "source": [
    "def dict_to_list(descriptions):\n",
    "    \"\"\"Convert dictionary to list of descriptions\"\"\"\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "    \"\"\"Create tokenizer for text\"\"\"\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(desc_list)\n",
    "    return tokenizer\n",
    "\n",
    "# Create and save tokenizer\n",
    "if os.path.exists('tokenizer.pkl'):\n",
    "    print(\"Loading existing tokenizer...\")\n",
    "    tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "else:\n",
    "    print(\"Creating tokenizer...\")\n",
    "    tokenizer = create_tokenizer(train_descriptions)\n",
    "    dump(tokenizer, open('tokenizer.pkl', 'wb'))\n",
    "    print(\"Tokenizer created and saved!\")\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33433353",
   "metadata": {},
   "source": [
    "## 13. Calculate Maximum Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6811a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 35\n"
     ]
    }
   ],
   "source": [
    "def max_length(descriptions):\n",
    "    \"\"\"Calculate maximum length of descriptions\"\"\"\n",
    "    desc_list = dict_to_list(descriptions)\n",
    "    return max(len(d.split()) for d in desc_list)\n",
    "\n",
    "max_length = max_length(train_descriptions)\n",
    "print(f\"Maximum sequence length: {max_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73e70b",
   "metadata": {},
   "source": [
    "## 14. Data Generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f255165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced data generator with label smoothing defined!\n"
     ]
    }
   ],
   "source": [
    "def create_sequences(tokenizer, max_length, desc_list, feature, vocab_size, label_smoothing=0.1):\n",
    "    \"\"\"Create input-output sequence pairs with optional label smoothing\"\"\"\n",
    "    X1, X2, y = [], [], []\n",
    "    for desc in desc_list:\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            # CRITICAL FIX: Use padding='post' for right-padding (required for cuDNN LSTM on GPU)\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length, padding='post')[0]\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            \n",
    "            # Apply label smoothing for better generalization\n",
    "            if label_smoothing > 0:\n",
    "                out_seq = out_seq * (1 - label_smoothing) + (label_smoothing / vocab_size)\n",
    "            \n",
    "            X1.append(feature)\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "def data_generator(descriptions, features, tokenizer, max_length, vocab_size, batch_size=32, label_smoothing=0.1):\n",
    "    \"\"\"Generate batches of data for training with label smoothing\"\"\"\n",
    "    def generator():\n",
    "        while True:\n",
    "            for key, description_list in descriptions.items():\n",
    "                if key not in features:\n",
    "                    continue\n",
    "                feature = features[key][0]\n",
    "                input_image, input_sequence, output_word = create_sequences(\n",
    "                    tokenizer, max_length, description_list, feature, vocab_size, label_smoothing\n",
    "                )\n",
    "                for i in range(len(input_image)):\n",
    "                    yield {'input_1': input_image[i], 'input_2': input_sequence[i]}, output_word[i]\n",
    "    \n",
    "    output_signature = (\n",
    "        {\n",
    "            'input_1': tf.TensorSpec(shape=(2048,), dtype=tf.float32),\n",
    "            'input_2': tf.TensorSpec(shape=(max_length,), dtype=tf.int32)\n",
    "        },\n",
    "        tf.TensorSpec(shape=(vocab_size,), dtype=tf.float32)\n",
    "    )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(generator, output_signature=output_signature)\n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Enhanced data generator with label smoothing defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434da2f0",
   "metadata": {},
   "source": [
    "## 15. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6996c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced model architecture with gating mechanism defined!\n"
     ]
    }
   ],
   "source": [
    "def define_model(vocab_size, max_length):\n",
    "    \"\"\"Define the enhanced image captioning model with attention-like mechanism\"\"\"\n",
    "    # Image feature input - Deeper processing with residual connection\n",
    "    inputs1 = Input(shape=(2048,), name='input_1')\n",
    "    fe1 = Dense(512, activation='relu')(inputs1)\n",
    "    fe2 = BatchNormalization()(fe1)\n",
    "    fe3 = Dropout(0.4)(fe2)\n",
    "    fe4 = Dense(512, activation='relu')(fe3)\n",
    "    fe5 = BatchNormalization()(fe4)\n",
    "    # Residual connection\n",
    "    fe_residual = add([fe1, fe4])\n",
    "    fe6 = Dense(256, activation='relu')(fe_residual)\n",
    "    \n",
    "    # Sequence input - Deeper LSTM with more capacity\n",
    "    inputs2 = Input(shape=(max_length,), name='input_2')\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.4)(se1)\n",
    "    # First LSTM layer with return_sequences\n",
    "    se3 = LSTM(512, return_sequences=True, recurrent_dropout=0.2)(se2)\n",
    "    se4 = BatchNormalization()(se3)\n",
    "    # Second LSTM layer\n",
    "    se5 = LSTM(512, return_sequences=False, recurrent_dropout=0.2)(se4)\n",
    "    se6 = BatchNormalization()(se5)\n",
    "    se7 = Dense(256, activation='relu')(se6)\n",
    "    \n",
    "    # Advanced decoder with gating mechanism (attention-like)\n",
    "    # Create a gating vector to weight image and text features\n",
    "    combined = concatenate([fe6, se7])\n",
    "    \n",
    "    # Gating mechanism - learns to balance image vs text importance\n",
    "    gate = Dense(256, activation='sigmoid', name='gate')(combined)\n",
    "    gated_image = multiply([fe6, gate])\n",
    "    gated_text = multiply([se7, gate])\n",
    "    \n",
    "    # Combine gated features\n",
    "    decoder1 = concatenate([gated_image, gated_text])\n",
    "    decoder2 = Dense(512, activation='relu')(decoder1)\n",
    "    decoder3 = BatchNormalization()(decoder2)\n",
    "    decoder4 = Dropout(0.5)(decoder3)\n",
    "    decoder5 = Dense(512, activation='relu')(decoder4)\n",
    "    decoder6 = BatchNormalization()(decoder5)\n",
    "    decoder7 = Dropout(0.5)(decoder6)\n",
    "    decoder8 = Dense(256, activation='relu')(decoder7)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder8)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    \n",
    "    # Use a more sophisticated optimizer configuration\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.0003,  # Slightly higher initial LR\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-7\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"Enhanced model architecture with gating mechanism defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe13e4eb",
   "metadata": {},
   "source": [
    "## 16. Create Model and View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2914fb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,873,408</span> │ input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │ input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ batch_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ add_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ batch_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], gate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], gate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7318</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,880,726</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_2 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_1 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,873,408\u001b[0m │ input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │       \u001b[38;5;34m1,049,088\u001b[0m │ input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m2,048\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m1,574,912\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],                │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │         \u001b[38;5;34m262,656\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │       \u001b[38;5;34m2,099,200\u001b[0m │ batch_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_12 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m2,048\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m131,328\u001b[0m │ add_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m131,328\u001b[0m │ batch_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gate (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m131,328\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], gate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multiply_1 (\u001b[38;5;33mMultiply\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], gate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │         \u001b[38;5;34m262,656\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m2,048\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │         \u001b[38;5;34m262,656\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m2,048\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m131,328\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7318\u001b[0m)              │       \u001b[38;5;34m1,880,726\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,800,854</span> (37.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,800,854\u001b[0m (37.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,795,734</span> (37.37 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,795,734\u001b[0m (37.37 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> (20.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,120\u001b[0m (20.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "Steps per epoch: 9596\n"
     ]
    }
   ],
   "source": [
    "model = define_model(vocab_size, max_length)\n",
    "print(model.summary())\n",
    "\n",
    "# Calculate training steps\n",
    "def get_steps_per_epoch(descriptions, batch_size=32):\n",
    "    total_sequences = 0\n",
    "    for img_captions in descriptions.values():\n",
    "        for caption in img_captions:\n",
    "            words = caption.split()\n",
    "            total_sequences += len(words) - 1\n",
    "    return max(1, total_sequences // batch_size)\n",
    "\n",
    "batch_size = 32\n",
    "steps_per_epoch = get_steps_per_epoch(train_descriptions, batch_size)\n",
    "print(f\"\\nSteps per epoch: {steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed9e66",
   "metadata": {},
   "source": [
    "## 17. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c63965ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced callbacks configured with learning rate warmup!\n"
     ]
    }
   ],
   "source": [
    "# Create models directory\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='models/best_model.keras',\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# More aggressive learning rate schedule\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.3,  # Reduce by 70%\n",
    "    patience=2,\n",
    "    min_lr=0.00000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Add early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=6,  # More patience for better convergence\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Add learning rate warmup using custom callback\n",
    "class WarmUpLearningRate(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, warmup_epochs=3, initial_lr=0.00003, target_lr=0.0003):\n",
    "        super(WarmUpLearningRate, self).__init__()\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.initial_lr = initial_lr\n",
    "        self.target_lr = target_lr\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch\n",
    "        if epoch < self.warmup_epochs:\n",
    "            # Gradually increase learning rate\n",
    "            lr = self.initial_lr + (self.target_lr - self.initial_lr) * (epoch / self.warmup_epochs)\n",
    "            # Fix for newer TensorFlow versions - use learning_rate instead of lr\n",
    "            self.model.optimizer.learning_rate.assign(lr)\n",
    "            print(f\"Warmup: Setting learning rate to {lr:.6f}\")\n",
    "\n",
    "warmup = WarmUpLearningRate(warmup_epochs=3, initial_lr=0.00003, target_lr=0.0003)\n",
    "\n",
    "print(\"Enhanced callbacks configured with learning rate warmup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce848c3",
   "metadata": {},
   "source": [
    "## 18. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3a0fd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced Training Configuration:\n",
      "  Epochs: 25\n",
      "  Batch size: 64 (increased for stability)\n",
      "  Steps per epoch: 4798\n",
      "  Vocabulary size: 7318\n",
      "  Max sequence length: 35\n",
      "\n",
      "Optimizations:\n",
      "  ✓ Gating mechanism for feature fusion\n",
      "  ✓ Residual connections in encoder\n",
      "  ✓ Deeper LSTM with recurrent dropout\n",
      "  ✓ Learning rate warmup (3 epochs)\n",
      "  ✓ Aggressive LR reduction on plateau\n",
      "\n",
      "Starting training...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Epoch 1/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1093 - loss: 6.7520\n",
      "Epoch 1: loss improved from None to 6.20228, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6330s\u001b[0m 1s/step - accuracy: 0.1347 - loss: 6.2023 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_1.keras\n",
      "\n",
      "Epoch 1 Results:\n",
      "  Loss: 6.2023\n",
      "  Accuracy: 0.1347 (13.47%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: inf\n",
      "\n",
      "============================================================\n",
      "Epoch 2/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.1770 - loss: 5.6722\n",
      "Epoch 1: loss improved from 6.20228 to 5.59886, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13191s\u001b[0m 3s/step - accuracy: 0.1902 - loss: 5.5989 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_2.keras\n",
      "\n",
      "Epoch 2 Results:\n",
      "  Loss: 5.5989\n",
      "  Accuracy: 0.1902 (19.02%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.6034\n",
      "\n",
      "============================================================\n",
      "Epoch 3/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2296 - loss: 5.2685\n",
      "Epoch 1: loss improved from 5.59886 to 5.22789, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13306s\u001b[0m 3s/step - accuracy: 0.2367 - loss: 5.2279 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_3.keras\n",
      "\n",
      "Epoch 3 Results:\n",
      "  Loss: 5.2279\n",
      "  Accuracy: 0.2367 (23.67%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.3710\n",
      "\n",
      "============================================================\n",
      "Epoch 4/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2589 - loss: 5.0217\n",
      "Epoch 1: loss improved from 5.22789 to 5.01202, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13344s\u001b[0m 3s/step - accuracy: 0.2612 - loss: 5.0120 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_4.keras\n",
      "\n",
      "Epoch 4 Results:\n",
      "  Loss: 5.0120\n",
      "  Accuracy: 0.2612 (26.12%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.2159\n",
      "\n",
      "============================================================\n",
      "Epoch 5/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2767 - loss: 4.8702\n",
      "Epoch 1: loss improved from 5.01202 to 4.86843, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13456s\u001b[0m 3s/step - accuracy: 0.2777 - loss: 4.8684 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_5.keras\n",
      "\n",
      "Epoch 5 Results:\n",
      "  Loss: 4.8684\n",
      "  Accuracy: 0.2777 (27.77%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.1436\n",
      "\n",
      "============================================================\n",
      "Epoch 6/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2925 - loss: 4.7518\n",
      "Epoch 1: loss improved from 4.86843 to 4.75291, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13783s\u001b[0m 3s/step - accuracy: 0.2933 - loss: 4.7529 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_6.keras\n",
      "\n",
      "Epoch 6 Results:\n",
      "  Loss: 4.7529\n",
      "  Accuracy: 0.2933 (29.33%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.1155\n",
      "\n",
      "============================================================\n",
      "Epoch 7/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3061 - loss: 4.6550\n",
      "Epoch 1: loss improved from 4.75291 to 4.65955, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6825s\u001b[0m 1s/step - accuracy: 0.3070 - loss: 4.6595 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_7.keras\n",
      "\n",
      "Epoch 7 Results:\n",
      "  Loss: 4.6595\n",
      "  Accuracy: 0.3070 (30.70%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0934\n",
      "\n",
      "============================================================\n",
      "Epoch 8/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975ms/step - accuracy: 0.3187 - loss: 4.5695\n",
      "Epoch 1: loss improved from 4.65955 to 4.57486, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4677s\u001b[0m 975ms/step - accuracy: 0.3183 - loss: 4.5749 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_8.keras\n",
      "\n",
      "Epoch 8 Results:\n",
      "  Loss: 4.5749\n",
      "  Accuracy: 0.3183 (31.83%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0847\n",
      "\n",
      "============================================================\n",
      "Epoch 9/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3293 - loss: 4.4980\n",
      "Epoch 1: loss improved from 4.57486 to 4.50455, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6797s\u001b[0m 1s/step - accuracy: 0.3283 - loss: 4.5045 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_9.keras\n",
      "\n",
      "Epoch 9 Results:\n",
      "  Loss: 4.5045\n",
      "  Accuracy: 0.3283 (32.83%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0703\n",
      "\n",
      "============================================================\n",
      "Epoch 10/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929ms/step - accuracy: 0.3386 - loss: 4.4324\n",
      "Epoch 1: loss improved from 4.50455 to 4.43973, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4459s\u001b[0m 929ms/step - accuracy: 0.3377 - loss: 4.4397 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_10.keras\n",
      "\n",
      "Epoch 10 Results:\n",
      "  Loss: 4.4397\n",
      "  Accuracy: 0.3377 (33.77%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0648\n",
      "\n",
      "============================================================\n",
      "Epoch 11/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3471 - loss: 4.3742\n",
      "Epoch 1: loss improved from 4.43973 to 4.38147, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7696s\u001b[0m 2s/step - accuracy: 0.3458 - loss: 4.3815 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_11.keras\n",
      "\n",
      "Epoch 11 Results:\n",
      "  Loss: 4.3815\n",
      "  Accuracy: 0.3458 (34.58%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0583\n",
      "\n",
      "============================================================\n",
      "Epoch 12/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3554 - loss: 4.3199\n",
      "Epoch 1: loss improved from 4.38147 to 4.32617, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6322s\u001b[0m 1s/step - accuracy: 0.3545 - loss: 4.3262 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_12.keras\n",
      "\n",
      "Epoch 12 Results:\n",
      "  Loss: 4.3262\n",
      "  Accuracy: 0.3545 (35.45%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0553\n",
      "\n",
      "============================================================\n",
      "Epoch 13/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3642 - loss: 4.2652\n",
      "Epoch 1: loss improved from 4.32617 to 4.27271, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5790s\u001b[0m 1s/step - accuracy: 0.3626 - loss: 4.2727 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_13.keras\n",
      "\n",
      "Epoch 13 Results:\n",
      "  Loss: 4.2727\n",
      "  Accuracy: 0.3626 (36.26%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0535\n",
      "\n",
      "============================================================\n",
      "Epoch 14/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3705 - loss: 4.2184\n",
      "Epoch 1: loss improved from 4.27271 to 4.22547, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7947s\u001b[0m 2s/step - accuracy: 0.3694 - loss: 4.2255 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_14.keras\n",
      "\n",
      "Epoch 14 Results:\n",
      "  Loss: 4.2255\n",
      "  Accuracy: 0.3694 (36.94%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0472\n",
      "\n",
      "============================================================\n",
      "Epoch 15/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3794 - loss: 4.1704\n",
      "Epoch 1: loss improved from 4.22547 to 4.17845, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7983s\u001b[0m 2s/step - accuracy: 0.3769 - loss: 4.1785 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_15.keras\n",
      "\n",
      "Epoch 15 Results:\n",
      "  Loss: 4.1785\n",
      "  Accuracy: 0.3769 (37.69%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0470\n",
      "\n",
      "============================================================\n",
      "Epoch 16/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3841 - loss: 4.1316\n",
      "Epoch 1: loss improved from 4.17845 to 4.13820, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8268s\u001b[0m 2s/step - accuracy: 0.3828 - loss: 4.1382 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_16.keras\n",
      "\n",
      "Epoch 16 Results:\n",
      "  Loss: 4.1382\n",
      "  Accuracy: 0.3828 (38.28%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0403\n",
      "\n",
      "============================================================\n",
      "Epoch 17/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3904 - loss: 4.0888\n",
      "Epoch 1: loss improved from 4.13820 to 4.09728, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8336s\u001b[0m 2s/step - accuracy: 0.3883 - loss: 4.0973 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_17.keras\n",
      "\n",
      "Epoch 17 Results:\n",
      "  Loss: 4.0973\n",
      "  Accuracy: 0.3883 (38.83%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0409\n",
      "\n",
      "============================================================\n",
      "Epoch 18/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3961 - loss: 4.0500\n",
      "Epoch 1: loss improved from 4.09728 to 4.05662, saving model to models/best_model.keras\n",
      "\u001b[1m4798/4798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5233s\u001b[0m 1s/step - accuracy: 0.3946 - loss: 4.0566 - learning_rate: 3.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Model saved: models/model_epoch_18.keras\n",
      "\n",
      "Epoch 18 Results:\n",
      "  Loss: 4.0566\n",
      "  Accuracy: 0.3946 (39.46%)\n",
      "  Learning Rate: 0.00003000\n",
      "  ✓ Improvement: 0.0407\n",
      "\n",
      "============================================================\n",
      "Epoch 19/25\n",
      "============================================================\n",
      "Warmup: Setting learning rate to 0.000030\n",
      "\u001b[1m   7/4798\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:23:58\u001b[0m 1s/step - accuracy: 0.4232 - loss: 3.8587"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 42\u001b[0m\n\u001b[0;32m     32\u001b[0m dataset \u001b[38;5;241m=\u001b[39m data_generator(\n\u001b[0;32m     33\u001b[0m     train_descriptions,\n\u001b[0;32m     34\u001b[0m     train_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     batch_size\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train for one epoch with all callbacks\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Save model after each epoch\u001b[39;00m\n\u001b[0;32m     51\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/model_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(begin_step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\jebar\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "epochs = 25  # More epochs with early stopping\n",
    "batch_size = 64  # Larger batch size for more stable gradients\n",
    "\n",
    "# Recalculate steps with new batch size\n",
    "steps_per_epoch = get_steps_per_epoch(train_descriptions, batch_size)\n",
    "\n",
    "print(f\"\\nEnhanced Training Configuration:\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"  Batch size: {batch_size} (increased for stability)\")\n",
    "print(f\"  Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"  Vocabulary size: {vocab_size}\")\n",
    "print(f\"  Max sequence length: {max_length}\")\n",
    "print(f\"\\nOptimizations:\")\n",
    "print(f\"  ✓ Gating mechanism for feature fusion\")\n",
    "print(f\"  ✓ Residual connections in encoder\")\n",
    "print(f\"  ✓ Deeper LSTM with recurrent dropout\")\n",
    "print(f\"  ✓ Learning rate warmup (3 epochs)\")\n",
    "print(f\"  ✓ Aggressive LR reduction on plateau\")\n",
    "print(f\"\\nStarting training...\\n\")\n",
    "\n",
    "# Train the model\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create fresh dataset for each epoch\n",
    "    dataset = data_generator(\n",
    "        train_descriptions,\n",
    "        train_features,\n",
    "        tokenizer,\n",
    "        max_length,\n",
    "        vocab_size,\n",
    "        batch_size\n",
    "    )\n",
    "    \n",
    "    # Train for one epoch with all callbacks\n",
    "    history = model.fit(\n",
    "        dataset,\n",
    "        epochs=1,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        callbacks=[checkpoint, reduce_lr, early_stop, warmup],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save model after each epoch\n",
    "    model_path = f\"models/model_epoch_{epoch + 1}.keras\"\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved: {model_path}\")\n",
    "    \n",
    "    # Save as latest\n",
    "    model.save(\"models/latest_model.keras\")\n",
    "    \n",
    "    # Print metrics\n",
    "    loss = history.history['loss'][0]\n",
    "    acc = history.history['accuracy'][0]\n",
    "    # Fix for newer TensorFlow versions - use learning_rate instead of lr\n",
    "    current_lr = float(model.optimizer.learning_rate.numpy())\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} Results:\")\n",
    "    print(f\"  Loss: {loss:.4f}\")\n",
    "    print(f\"  Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"  Learning Rate: {current_lr:.8f}\")\n",
    "    \n",
    "    # Track improvement\n",
    "    if loss < best_loss:\n",
    "        improvement = best_loss - loss\n",
    "        best_loss = loss\n",
    "        patience_counter = 0\n",
    "        print(f\"  ✓ Improvement: {improvement:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"  ⚠ No improvement (patience: {patience_counter}/6)\")\n",
    "    \n",
    "    # Check if early stopping triggered\n",
    "    if early_stop.stopped_epoch > 0:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "        print(f\"Best loss achieved: {best_loss:.4f}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training completed!\")\n",
    "print(f\"Final best loss: {best_loss:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
